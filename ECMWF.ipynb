{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45de6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Authenticate(auth_mode='notebook')\n",
    "ee.Initialize(project='global-booster-421311')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b44309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2002...\n",
      "Export started for 2002! Monitor in GEE Tasks.\n",
      "Processing year 2003...\n",
      "Export started for 2003! Monitor in GEE Tasks.\n",
      "Processing year 2004...\n",
      "Export started for 2004! Monitor in GEE Tasks.\n",
      "Processing year 2005...\n",
      "Export started for 2005! Monitor in GEE Tasks.\n",
      "Processing year 2006...\n",
      "Export started for 2006! Monitor in GEE Tasks.\n",
      "Processing year 2007...\n",
      "Export started for 2007! Monitor in GEE Tasks.\n",
      "Processing year 2008...\n",
      "Export started for 2008! Monitor in GEE Tasks.\n",
      "Processing year 2009...\n",
      "Export started for 2009! Monitor in GEE Tasks.\n",
      "Processing year 2010...\n",
      "Export started for 2010! Monitor in GEE Tasks.\n",
      "Processing year 2011...\n",
      "Export started for 2011! Monitor in GEE Tasks.\n",
      "Processing year 2012...\n",
      "Export started for 2012! Monitor in GEE Tasks.\n",
      "Processing year 2013...\n",
      "Export started for 2013! Monitor in GEE Tasks.\n",
      "Processing year 2014...\n",
      "Export started for 2014! Monitor in GEE Tasks.\n",
      "Processing year 2015...\n",
      "Export started for 2015! Monitor in GEE Tasks.\n",
      "Processing year 2016...\n",
      "Export started for 2016! Monitor in GEE Tasks.\n",
      "Processing year 2017...\n",
      "Export started for 2017! Monitor in GEE Tasks.\n",
      "Processing year 2018...\n",
      "Export started for 2018! Monitor in GEE Tasks.\n",
      "Processing year 2019...\n",
      "Export started for 2019! Monitor in GEE Tasks.\n",
      "Processing year 2020...\n",
      "Export started for 2020! Monitor in GEE Tasks.\n",
      "Processing year 2021...\n",
      "Export started for 2021! Monitor in GEE Tasks.\n",
      "Processing year 2022...\n",
      "Export started for 2022! Monitor in GEE Tasks.\n",
      "All yearly exports started! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "catchments = ee.FeatureCollection('projects/global-booster-421311/assets/LakeCatchments_NA')\n",
    "\n",
    "variables_mean = [\n",
    "    'temperature_2m',\n",
    "    'lake_mix_layer_temperature'\n",
    "]\n",
    "variables_sum = [\n",
    "    'total_precipitation_sum',\n",
    "    'surface_runoff_sum',\n",
    "    'runoff_sum'\n",
    "]\n",
    "export_fields = [\n",
    "    'Lake_ID', 'year', 'week', 'week_start', 'week_end',\n",
    "    'temperature_2m',\n",
    "    'lake_mix_layer_temperature',\n",
    "    'total_precipitation_sum',\n",
    "    'surface_runoff_sum',\n",
    "    'runoff_sum'\n",
    "]\n",
    "\n",
    "def features_for_week(era, year, week):\n",
    "    week = ee.Number(week)\n",
    "    start_day = week.subtract(1).multiply(7)\n",
    "    end_day = week.multiply(7).subtract(1)\n",
    "    start_date = ee.Date(f'{year}-01-01').advance(start_day, 'day')\n",
    "    end_date = ee.Date(f'{year}-01-01').advance(end_day, 'day')\n",
    "    week_imgs = era.filterDate(start_date, end_date.advance(1, 'day'))\n",
    "    mean_img = week_imgs.mean().select(variables_mean)\n",
    "    sum_img = week_imgs.sum().select(variables_sum)\n",
    "    stack = mean_img.addBands(sum_img)\n",
    "    stats = stack.reduceRegions(\n",
    "        collection=catchments,\n",
    "        reducer=ee.Reducer.mean().forEachBand(mean_img)\n",
    "                .combine(ee.Reducer.sum().forEachBand(sum_img), '', False),\n",
    "        scale=10000\n",
    "    ).map(lambda f: f.set({\n",
    "        'year': year,\n",
    "        'week': week,\n",
    "        'week_start': start_date.format('YYYY/MM/dd'),\n",
    "        'week_end': end_date.format('YYYY/MM/dd')\n",
    "    }))\n",
    "    return stats\n",
    "\n",
    "def drop_geometry(feature):\n",
    "    return feature.setGeometry(None)\n",
    "\n",
    "years = list(range(2002, 2023))  # 2002 to 2022\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing year {year}...\")\n",
    "    era = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR').filterDate(f'{year}-01-01', f'{year+1}-01-01')\n",
    "    weeks = list(range(1, 54))\n",
    "    weekly_collections = ee.List(weeks).map(lambda w: features_for_week(era, year, ee.Number(w)))\n",
    "    all_features = ee.FeatureCollection(weekly_collections).flatten()\n",
    "    all_features_no_geom = all_features.map(drop_geometry)\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=all_features_no_geom.select(export_fields),\n",
    "        description=f'ERA5Land_Weekly_Catchments_{year}_Climate',\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Export started for {year}! Monitor in GEE Tasks.\")\n",
    "\n",
    "print(\"All yearly exports started! ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36bb5fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8452\\837366890.py:4: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  folder = \"Datasets\\ECMWF_raw\"  # adjust if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2002_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2003_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2004_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2005_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2006_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2007_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2008_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2009_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2010_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2011_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2012_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2013_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2014_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2015_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2016_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2017_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2018_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2019_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2020_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2021_Climate.csv\n",
      "âœ… Cleaned and exported: ERA5Land_Weekly_Catchments_2022_Climate.csv\n",
      "ðŸŽ‰ All ERA5 weekly climate CSVs cleaned and sorted!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder = \"Datasets\\ECMWF_raw\"  # adjust if needed\n",
    "\n",
    "for fname in os.listdir(folder):\n",
    "    if fname.startswith('ERA5Land_Weekly_Catchments_') and fname.endswith('.csv'):\n",
    "        fpath = os.path.join(folder, fname)\n",
    "        df = pd.read_csv(fpath)\n",
    "\n",
    "        # Drop unwanted columns if present\n",
    "        to_drop = ['.geo', 'system:index']\n",
    "        df = df.drop(columns=[col for col in to_drop if col in df.columns])\n",
    "\n",
    "        # Desired column order\n",
    "        main_cols = ['Lake_ID', 'year', 'week', 'week_start', 'week_end']\n",
    "        other_cols = [col for col in df.columns if col not in main_cols]\n",
    "        df = df[main_cols + other_cols]\n",
    "\n",
    "        # Sort by Lake_ID and date (year, week)\n",
    "        df = df.sort_values(by=['Lake_ID', 'year', 'week'])\n",
    "\n",
    "        # Save cleaned table (overwrite or add suffix if you prefer)\n",
    "        df.to_csv(fpath, index=False)\n",
    "        print(f\"âœ… Cleaned and exported: {fname}\")\n",
    "\n",
    "print(\"ðŸŽ‰ All ERA5 weekly climate CSVs cleaned and sorted!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
