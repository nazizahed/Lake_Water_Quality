{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19ae3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è 0 lakes didn‚Äôt intersect any catchment. Assigning nearest catchment...\n",
      "‚úÖ Final cleaned shapefile saved: Datasets/final/lake_catchments_na_cleaned.shp\n",
      "üéØ Unique Lake_IDs: 466\n",
      "‚ùó Unmatched lakes that used nearest: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fiona\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "# === CONFIG ===\n",
    "catchment_files = [\n",
    "    \"Datasets/na/hybas_lake_na_lev08_v1c.shp\"\n",
    "]\n",
    "lake_file = \"Datasets/lakes/CCILakesV202.shp\"\n",
    "lake_id_column = \"Lake_ID\"\n",
    "output_file = \"Datasets/final/lake_catchments_na_cleaned.shp\"\n",
    "\n",
    "# === STEP 1: Load and clean HydroBASINS catchments ===\n",
    "def clean_geometries(gdf):\n",
    "    cleaned = []\n",
    "    for geom in gdf.geometry:\n",
    "        if geom is None:\n",
    "            cleaned.append(None)\n",
    "        elif geom.geom_type in [\"Polygon\", \"MultiPolygon\"]:\n",
    "            cleaned.append(geom)\n",
    "        elif geom.geom_type == \"GeometryCollection\":\n",
    "            polys = [g for g in geom.geoms if isinstance(g, (Polygon, MultiPolygon))]\n",
    "            cleaned.append(polys[0] if polys else None)\n",
    "        else:\n",
    "            cleaned.append(None)\n",
    "    gdf[\"geometry\"] = cleaned\n",
    "    return gdf[~gdf[\"geometry\"].isnull()]\n",
    "\n",
    "catchments_cleaned = []\n",
    "for path in catchment_files:\n",
    "    raw = gpd.read_file(path)\n",
    "    cleaned = clean_geometries(raw)\n",
    "    catchments_cleaned.append(cleaned)\n",
    "\n",
    "catchments_gdf = gpd.GeoDataFrame(pd.concat(catchments_cleaned, ignore_index=True), crs=cleaned.crs)\n",
    "\n",
    "# === STEP 2: Load lakes and spatially clip to HydroBASINS area ===\n",
    "lakes_gdf = gpd.read_file(lake_file).to_crs(catchments_gdf.crs)\n",
    "lakes_clipped = gpd.clip(lakes_gdf, catchments_gdf)\n",
    "\n",
    "# === STEP 3: Assign lakes to catchments ===\n",
    "def assign_lakes_to_catchments(catchments_gdf, lakes_gdf, lake_id_column):\n",
    "    lakes_gdf = lakes_gdf.to_crs(catchments_gdf.crs)\n",
    "    intersecting = gpd.sjoin(catchments_gdf, lakes_gdf[[lake_id_column, 'geometry']], how='inner', predicate='intersects')\n",
    "    intersecting['match_method'] = 'intersect'\n",
    "    matched_ids = set(intersecting[lake_id_column])\n",
    "    unmatched = lakes_gdf[~lakes_gdf[lake_id_column].isin(matched_ids)].copy()\n",
    "    print(f\"‚ÑπÔ∏è {len(unmatched)} lakes didn‚Äôt intersect any catchment. Assigning nearest catchment...\")\n",
    "\n",
    "    if not unmatched.empty:\n",
    "        projected_crs = \"EPSG:3395\"\n",
    "        unmatched = unmatched.to_crs(projected_crs)\n",
    "        catchments_proj = catchments_gdf.to_crs(projected_crs)\n",
    "        unmatched[\"geometry\"] = unmatched.geometry.centroid\n",
    "\n",
    "        nearest = gpd.sjoin_nearest(\n",
    "            unmatched[[lake_id_column, 'geometry']],\n",
    "            catchments_proj,\n",
    "            how='left',\n",
    "            distance_col=\"dist_to_catchment\"\n",
    "        )\n",
    "        nearest['match_method'] = 'nearest'\n",
    "        nearest = nearest.to_crs(catchments_gdf.crs)\n",
    "        result = pd.concat([intersecting, nearest], ignore_index=True)\n",
    "    else:\n",
    "        result = intersecting\n",
    "\n",
    "    return result, unmatched\n",
    "\n",
    "lake_catchments, unmatched_lakes = assign_lakes_to_catchments(catchments_gdf, lakes_clipped, lake_id_column)\n",
    "\n",
    "# === STEP 4: Clean up final lake_catchments\n",
    "lake_catchments[lake_id_column] = lake_catchments[lake_id_column].astype(float)\n",
    "\n",
    "# Restore lake polygon geometries (in case any are centroids from nearest)\n",
    "lake_polygons = lakes_clipped.set_index(lake_id_column)[[\"geometry\"]]\n",
    "lake_catchments[\"geometry\"] = lake_catchments[lake_id_column].map(lake_polygons[\"geometry\"])\n",
    "\n",
    "# Remove any duplicate join columns or repeat rows\n",
    "lake_catchments = lake_catchments.loc[:, ~lake_catchments.columns.duplicated()]\n",
    "lake_catchments = lake_catchments.drop(columns=[c for c in lake_catchments.columns if c.lower().startswith(\"index_\") or c.lower().startswith(\"dist_\")], errors=\"ignore\")\n",
    "lake_catchments = lake_catchments.drop_duplicates(subset=[\"Lake_ID\", \"HYBAS_ID\", \"geometry\"])\n",
    "\n",
    "# Final geometry validation (only polygons)\n",
    "lake_catchments = clean_geometries(lake_catchments)\n",
    "\n",
    "# === STEP 5: Save to shapefile using Fiona (with large Lake_ID float) ===\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "lake_catchments = lake_catchments.rename(columns=lambda x: x[:10])\n",
    "schema = gpd.io.file.infer_schema(lake_catchments)\n",
    "schema['properties']['Lake_ID'] = 'float:18.0'\n",
    "\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "lake_catchments.to_file(output_file, driver=\"ESRI Shapefile\", engine=\"fiona\", schema=schema)\n",
    "\n",
    "print(f\"‚úÖ Final cleaned shapefile saved: {output_file}\")\n",
    "print(f\"üéØ Unique Lake_IDs: {lake_catchments['Lake_ID'].nunique()}\")\n",
    "print(f\"‚ùó Unmatched lakes that used nearest: {len(unmatched_lakes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0e209fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Expected number of lakes in HydroBASINS area: 466\n",
      "‚úÖ Lake_IDs assigned to catchments: 466\n",
      "‚úÖ All lakes in the HydroBASINS area have been assigned to catchments.\n"
     ]
    }
   ],
   "source": [
    "expected_lakes = lakes_clipped[\"Lake_ID\"].nunique()\n",
    "print(f\"üéØ Expected number of lakes in HydroBASINS area: {expected_lakes}\")\n",
    "assigned_lakes = lake_catchments[\"Lake_ID\"].nunique()\n",
    "print(f\"‚úÖ Lake_IDs assigned to catchments: {assigned_lakes}\")\n",
    "if expected_lakes == assigned_lakes:\n",
    "    print(\"‚úÖ All lakes in the HydroBASINS area have been assigned to catchments.\")\n",
    "else:\n",
    "    print(f\"‚ùå Mismatch: {expected_lakes - assigned_lakes} lakes are missing from the final output.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
